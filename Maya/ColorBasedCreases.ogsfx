#version 410

#include "Utility.ogsfh"
#include "Settings.ogsfh"

attribute appdata {
    vec3 position       : POSITION;
	vec3 normal         : NORMAL;
    vec4 color          : COLOR0;
    vec2 uv             : TEXCOORD0;
};
 
attribute vs_to_gs {
    vec4 worldPosition  : POSITION;
	vec3 normal         : NORMAL;
    vec3 uv             : TEXCOORD0;
    vec4 color          : TEXCOORD1;
    vec4 data1          : TEXCOORD2;
    int id              : TEXCOORD3;
};

attribute gs_to_ps {
    vec4 worldPosition  : POSITION;
	vec3 worldNormal    : NORMAL;
    vec3 uv             : TEXCOORD0;
    vec4 color          : TEXCOORD1;

    // encoded data, meaning changes based on the generator of the vertex.
    // color.a defines the encoding (normal face, silhouette, crease)
    // normal face: xyz is the distance to the opposite edge (for wireframe drawing)
    // silhouette: TBD
    // crease: xy is the crease edge start position, zw is end position
    // vec4 encoded : TEXCOORD1;
    vec4 dist           : TEXCOORD2;
};

attribute ps_out {
    vec4 color          : COLOR0;
};

GLSLShader VS
{
    void main()
    {
        o.worldPosition = u_ModelMatrix * vec4(position, 1);
        o.normal = normal; // (u_ModelMatrix * vec4(normal, 0)).xyz;
        o.color = color; // color.aaaa; // temp swizzle of alpha in every color bit for debug
        o.uv = vec3(uv, 0);
        o.id = gl_VertexID; // Used for crease detection

        vec4 camPos = u_CameraMatrix[3]; 
        
        o.data1.xyz = position;
        
        // NdotV of the vertex
        o.data1.w = dot(u_ModelMatrix * vec4(normal, 0), camPos - o.worldPosition);

        // gl_Position = u_MVPMatrix * vec4(position, 1);
    }
}

GLSLShader GS
{
    layout(triangles_adjacency) in;
    layout(triangle_strip, max_vertices = 32) out;

    float distanceToLine(vec3 point, vec3 a, vec3 b)
    {
        return length(cross(point - a, point - b)) / length(b - a);
    }

    float area(vec3 v0, vec3 v1, vec3 v2) 
    {
        return length(cross(v2 - v0, v2 - v1)) * 0.5;
    }

    vec3 xprime(float di, float dj, vec3 xi, vec3 xj) {
        float L = abs(di) + abs(dj);
        return (abs(dj) / L) * xi + (abs(di) / L) * xj;
    }

    void drawCreaseDebug(vec4 v0, vec4 v1, vec3 n0, vec3 n1)
    {
        vec3 start = v0.xyz + normalize(n0) * 0.01;
        vec3 end = v1.xyz + normalize(n1) * 0.01;
        vec3 right = start + normalize(cross(start - end, n0)) * 0.1;

        gl_Position = u_ViewProjMatrix * vec4(start, 1);
        EmitVertex();

        gl_Position = u_ViewProjMatrix * vec4(end, 1);
        EmitVertex();

        gl_Position = u_ViewProjMatrix * vec4(right, 1);
        EmitVertex();

        EndPrimitive();
    }

    bool isBackface(vec3 v0, vec3 v1, vec3 v2) {
        vec3 N = cross(v1 - v0, v2 - v0);
        vec3 center = (v0 + v1 + v2) / 3;
        return dot(center - u_CameraMatrix[3].xyz, N) >= 0;
    }

    /**
     * Where the vertices are already in clip space
     */
    // void emitQuad(vec2 v[4])
    // {
    //     for (int idx = 0; idx < 4; idx++) {
    //         gl_Position = v[idx];
    //         EmitVertex();
    //     }

    //     EndPrimitive();
    // }

    /**
     * Draw a screen-space (billboarded) arrow pointing 
     * at the given world space position
     */
    void drawVertexMarker(vec4 v) 
    {
        v = u_ViewProjMatrix * v;
        
        // Extract aspect ratio from the projection matrix
        // where m00 = 1/(aspect * tan(FOV / 2)) and m11 = 1/tan(FOV / 2)
        float aspect = u_ProjMatrix[0][0] / u_ProjMatrix[1][1];

        gl_Position = v;
        EmitVertex();

        // add some extra verts for testing
        gl_Position = v + vec4(-0.1 * aspect, 0.1, 0, 0);
        EmitVertex();
        
        gl_Position = v + vec4(0.1 * aspect, 0.1, 0, 0);
        EmitVertex();

        EndPrimitive();
    }

    struct SilhouetteInfo {
        bool valid;
        int permutation;

        vec3 startPos;
        vec3 endPos;
        vec3 startNormal;
        vec3 endNormal;
    };

    /**
     * Calculate silhouette edge information for the input triangle
     */
    SilhouetteInfo getSilhouetteInfo() {
        float L;

        int i0 = 0;
        int i1 = 2;
        int i2 = 4;

        // NdotV values of each vertex
        float d0 = gsin[i0].data1.w;
        float d1 = gsin[i1].data1.w;
        float d2 = gsin[i2].data1.w;

        // Offset NdotV by 0.1 so we always have a nonzero.
        // .: +1 for >= 0, -1 for < 0
        float s0 = sign(d0 + 0.0001);
        float s1 = sign(d1 + 0.0001);
        float s2 = sign(d2 + 0.0001);

        // Local vertex positions
        vec3 v0 = gsin[i0].data1.xyz;
        vec3 v1 = gsin[i1].data1.xyz;
        vec3 v2 = gsin[i2].data1.xyz;

        vec3 n0 = gsin[i0].normal;
        vec3 n1 = gsin[i1].normal;
        vec3 n2 = gsin[i2].normal;

        // Naive method : ALL permutations 

        SilhouetteInfo s;
        s.valid = true;

        if (s0 != s1 && s0 != s2) {
            // start is s2 to s0, end is s2 to s1
            s.permutation = 1;

            // Weighted silhouette points
            s.startPos = xprime(d0, d1, v0, v1);
            s.endPos = xprime(d0, d2, v0, v2);

            // Normal is the interp of the two end normals
            L = distance(v0, s.startPos) / distance(v0, v1);
            s.startNormal = lerp(n0, n1, L);

            L = distance(v0, s.endPos) / distance(v0, v2);
            s.endNormal = lerp(n0, n2, L);
        }
        else if (s1 != s0 && s1 != s2) {
            s.permutation = 2;
            
            s.startPos = xprime(d1, d0, v1, v0);
            s.endPos = xprime(d1, d2, v1, v2);

            L = distance(v1, s.startPos) / distance(v1, v0);
            s.startNormal = lerp(n1, n0, L);

            L = distance(v1, s.endPos) / distance(v1, v2);
            s.endNormal = lerp(n1, n2, L);
        }
        else if (s2 != s0 && s2 != s1) {
            s.permutation = 3;

            s.startPos = xprime(d2, d0, v2, v0);
            s.endPos = xprime(d2, d1, v2, v1);

            L = distance(v2, s.startPos) / distance(v2, v0);
            s.startNormal = lerp(n2, n0, L);

            L = distance(v2, s.endPos) / distance(v2, v1);
            s.endNormal = lerp(n2, n1, L);
        }
        else {
            s.valid = false;
        }

        return s;
    }

    void legacy_drawSilhouette(SilhouetteInfo s) {
        // vec3 up = s.endPos - s.startPos;
        // vec3 look = u_CameraMatrix[3].xyz - s.startPos;
        // look.y = 0;
        // look = normalize(look);
        // up = normalize(up);
        // vec3 right = cross(up, look);
        vec3 v[4];
        vec3 camPos = u_CameraMatrix[3].xyz;

        float startScale = u_SilhouetteScale;
        float endScale = u_SilhouetteScale;

        if (u_OutlineViewSpaceScale) {
            startScale *= distance(s.startPos, camPos) * 0.1;
            endScale *= distance(s.endPos, camPos) * 0.1;
        }

        // TODO: ns/ne should NOT be perpendicular to the face normal that we're drawing along.
        // instead, this should be flush with the view space.
        v[0] = vec3(s.startPos + startScale * normalize(s.startNormal));
        v[1] = vec3(s.endPos + endScale * normalize(s.endNormal));
        v[2] = vec3(s.startPos);
        v[3] = vec3(s.endPos);

        o.color = vec4(u_OutlineColor, 0);

        // TODO: Set o.worldNormal for silhouette edges

        // Debug out original facing directions before the flip
        // (red is forward, green is reversed)
        // if (u_Debug) {
        //     if (NdotV > 0) {
        //         o.col = vec4(1, 0, 0, 1);
        //     } else if (NdotV < 0) {
        //         o.col = vec4(0, 1, 0, 1);
        //     }
        // }

        if (!isBackface(v[0], v[1], v[2])) {
            for (int i = 0; i < 4; i++) {
                gl_Position = u_MVPMatrix * vec4(v[i], 1.0);
                EmitVertex();
            }
        } else {
            // Flip winding order of the quad
            gl_Position = u_MVPMatrix * vec4(v[1], 1.0);
            EmitVertex();
            
            gl_Position = u_MVPMatrix * vec4(v[0], 1.0);
            EmitVertex();
            
            gl_Position = u_MVPMatrix * vec4(v[3], 1.0);
            EmitVertex();
            
            gl_Position = u_MVPMatrix * vec4(v[2], 1.0);
            EmitVertex();
        }
        
        EndPrimitive();
    }

    /**
     * Add a screen space billboard to represent a crease/silhouette edge.
     *
     * @param vec4  v0          Start vertex in world space
     * @param vec4  v1          End vertex in world space
     * @param vec3  n0          Start vertex's normal in world space
     * @param vec3  n1          End vertex's normal in world space
     * @param float scale       Uniform thickness scale
     * @param float thickness0  Multiplier scale at the start vertex (0 -> 1)
     * @param float thickness1  Multiplier scale at the end vertex (0 -> 1)
     */
    void drawEdge(
        vec4 v0, 
        vec4 v1, 
        vec3 n0, 
        vec3 n1, 
        float scale, 
        float thickness0, 
        float thickness1
    ) {
        vec4 camPos = u_CameraMatrix[3];
        
        float scale0 = scale; 
        float scale1 = scale; 

        // v0 += normalize(camPos - v0) * u_SurfaceInsetScale;
        // v1 += normalize(camPos - v1) * u_SurfaceInsetScale;

        // Scale linearly with distance in view space
        if (u_OutlineViewSpaceScale) {
            scale0 *= distance(v0, camPos) * 0.1;
            scale1 *= distance(v1, camPos) * 0.1;
        }

        // Offset input vertices by their normals to use as the
        // origin edge for the crease to be adjacent to
        v0.xyz += n0 * scale0 * u_SurfaceInsetScale;
        v1.xyz += n1 * scale1 * u_SurfaceInsetScale;
        
        // Apply per-end thickness scaling for variations in edge widths
        scale0 *= thickness0;
        scale1 *= thickness1;

        // Extract aspect ratio from the projection matrix
        // where m00 = 1/(aspect * tan(FOV / 2)) and m11 = 1/tan(FOV / 2)
        float aspect = u_ProjMatrix[0][0] / u_ProjMatrix[1][1];
        float halfW0 = scale0 * 0.5;
        float halfW1 = scale1 * 0.5;

        // Offset crease edge by the source edge's normal direction  
        // scaled by the thickness of the crease we're going to draw.
        // The 0.1 factor is to always keep it intersecting the surface
        // geometry a little bit and not entirely fly off.
        // TODO: This is incorrect - as we should instead perfectly align with the 
        // geometry. Otherwise, intersections cause roundedness within edges.
        // v0 = v0 + vec4(normalize(n0) * u_CreaseScale * 0.1, 0);
        // v1 = v1 + vec4(normalize(n1) * u_CreaseScale * 0.1, 0);

        // Convert points to projected + normalized device coords [-1, 1]
        vec4 p0 = u_ViewProjMatrix * v0;
        vec4 p1 = u_ViewProjMatrix * v1;

        vec2 s0 = p0.xy / p0.w;
        vec2 s1 = p1.xy / p1.w;

        // Push projected z-depth toward the camera
        // can't though - shows geo behind our mesh.
        // p0.z -= 0.1;
        // p1.z -= 0.1;

        // Correct for aspect ratio
        s0.x /= aspect;
        s1.x /= aspect;

        // Generate a right vector perpendicular to our forward direction in NDC
        vec2 forward = normalize(s1 - s0);
        vec2 right = vec2(-forward.y, forward.x);

        // Encode as a generated crease vertex
        // TODO: Distance should be encoded as well instead of in the
        // fragment shader so GL can interp. but fuck it, will do later.
        // o.dist = vec4(p0.xy, p1.xy);
        
        vec2 segmentDir = p0.xy - p1.xy;
        segmentDir.x /= aspect;

        float segmentLen = length(segmentDir);
        float uvSegmentLen = segmentLen / (scale1 + segmentLen);
        
        float uvHalfW = (1.0 - uvSegmentLen) * 0.5;

        // Z channel is screen space segment length
        o.uv.z = uvHalfW;

        vec4 aspectCorrect = vec4(aspect, 1, 0, 0);

        // vec4 viewPos = u_ViewMatrix * v0;
        // float depth = -viewPos.z;

        float zoffset = -u_OutlineOffset;//-halfW0;

        gl_Position = p0 + (vec4(right, 0, 0) * -halfW0 + vec4(forward, 0, 0) * -halfW0) * aspectCorrect;
        o.worldPosition = vec4(gl_Position.xy, 0, 1);
        o.uv.xy = vec2(0, 0);
        
        gl_Position.z += zoffset;
        o.dist = vec4(0,0,0, gl_Position.z);
        EmitVertex();

        gl_Position = p1 + (vec4(right, 0, 0) * -halfW1 + vec4(forward, 0, 0) * halfW1) * aspectCorrect;
        o.worldPosition = vec4(gl_Position.xy, 0, 1);
        o.uv.xy = vec2(1, 0);
        
        gl_Position.z += zoffset;
        o.dist = vec4(0,0,0, gl_Position.z);
        EmitVertex();

        gl_Position = p0 + (vec4(right, 0, 0) * halfW0 + vec4(forward, 0, 0) * -halfW0) * aspectCorrect;
        o.worldPosition = vec4(gl_Position.xy, 0, 1);
        o.uv.xy = vec2(0, 1);
        
        gl_Position.z += zoffset;
        o.dist = vec4(0,0,0, gl_Position.z);
        EmitVertex();
        
        gl_Position = p1 + (vec4(right, 0, 0) * halfW1 + vec4(forward, 0, 0) * halfW1) * aspectCorrect;
        o.worldPosition = vec4(gl_Position.xy, 0, 1);
        o.uv.xy = vec2(1, 1);
        
        gl_Position.z += zoffset;
        o.dist = vec4(0,0,0, gl_Position.z);
        EmitVertex();

        EndPrimitive();
    }

    /**
     * Calculate distance between a vertex and its opposite edge
     *
     * See: Bærentzen, J. A., Munk-Lund, S., Gjøl, M., & Larsen, B. D. (2008). 
     * Two Methods for Antialiased Wireframe Drawing with Hidden Line Removal. 
     * http://orbit.dtu.dk/files/3735323/wire-sccg.pdf
     *
     * @param int idx Vertex index in the GS input
     * 
     * @return vec3
     */
    vec3 getOppositeEdgeDistanceVec(int idx) {
        int nextIdx = (idx + 2) % 6;
        int nextIdx2 = (nextIdx + 2) % 6;

        // Vertex to edge distance calculations for wireframe rendering
        // as part of our fragment coloring (instead of a separate technique)
        vec4 v0 = u_ViewProjMatrix * gsin[idx].worldPosition;
        vec4 v1 = u_ViewProjMatrix * gsin[nextIdx].worldPosition;
        vec4 v2 = u_ViewProjMatrix * gsin[nextIdx2].worldPosition;

        float d = distanceToLine(v0.xyz, v1.xyz, v2.xyz);

        if (idx == 0) {
            return vec3(d, 0, 0);
        } else if (idx == 2) {
            return vec3(0, d, 0);
        } else {
            return vec3(0, 0, d);
        }
    }

    /**
     * Determine if there is a valid crease line between the two input vertices.
     * 
     * Creases are defined by alpha painting the vertex colors as well as the 
     * vertex ID ordering to ensure that the same crease isn't drawn by adjacent
     * triangles that operate on the same edge.
     *
     * Vertex alpha painting may also be different levels to indicate what
     * LOD the crease should be visible within. 
     *
     * This MASSIVELY assumes the vertex indices match winding order.
     *
     * @param int idx Index of crease start vertex in GS inputs
     * @param int nextIdx Index of crease end vertex in GS inputs
     * @param int lod Current LOD to check against
     *
     * @return boolean
     */
    bool isValidCrease(int idx, int nextIdx, int lod) {
        // TODO: less hardcoding.
        float low = 0.10; // LOD0 - 0.1X

        if (lod == 1) { // LOD1 - 0.2X
            low = 0.20;
        } else if (lod == 2) { // LOD2 - 0.3X
            low = 0.30;
        }

        // Alpha digits follow the pattern:
        // 0.LBTT where:
        // L - LOD level 
        // B - "Bump" value (1 or 0) - Only 0's and 0-1 can connect.
        // TT - Thickness from 0 to 99 (later normalized)

        float a = gsin[idx].color.a;
        float b = gsin[nextIdx].color.a;

        int aLOD = int(floor(a * 10));
        int bLOD = int(floor(b * 10));

        int aBump = int(floor(a * 100)) - aLOD * 10;
        int bBump = int(floor(b * 100)) - bLOD * 10;
        
        // Increasing vertex IDs, both at *least* the 
        // input LOD, *and* one of them is an exact 
        // crease vertex (0.X0)
        return (gsin[idx].id < gsin[nextIdx].id) &&
            (aLOD >= lod + 1 && bLOD >= lod + 1) &&
            (aBump == 0 || bBump == 0);
    }

    /**
     * Draw the base triangle input
     */
    void drawInputGeometry() {
        // triadj - 0, 2, 4 indices
        for (int idx = 0; idx < 6; idx += 2) {
            // Color without the type encoding
            // TODO: RGB here has no usage, since we're using
            // a uniform for color data. Reuse for something?
            o.color = vec4(gsin[idx].color.rgb, 0);
            o.worldNormal = (u_ModelMatrix * vec4(gsin[idx].normal, 0)).xyz;
            o.worldPosition = gsin[idx].worldPosition;
            o.uv = gsin[idx].uv;

            // slight inset
            // o.worldPosition.xyz -= normalize(gsin[idx].normal) * u_SurfaceInsetScale;

            // vec4 viewPos = u_ViewMatrix * o.worldPosition;
            // float depth = -viewPos.z;

            // o.color = vec4(vec3(depth), 0);
            gl_Position = u_ViewProjMatrix * o.worldPosition;
            // gl_Position.z = depth;
            
            // Calculate opposite edge distance per vertex for wireframing
            o.dist = vec4(getOppositeEdgeDistanceVec(idx), gl_Position.z);
            // TODO: throwing z as a rider to test render :^)
            EmitVertex();
        }

        EndPrimitive();
    }

    /**
     * Retrieve LOD of the current model
     */
    int getLOD() {
        vec4 origin = u_ModelMatrix * vec4(0, 0, 0, 1);
        float d = distance(u_CameraMatrix[3], origin);

        int lod = 0;
        if (d > u_LOD2Distance) {
            lod = 2;
        } else if (d > u_LOD1Distance) {
            lod = 1;
        }

        return lod;
    }

    void main() {
        if (u_GeometryDrawMode > 0) {
            drawInputGeometry();
        }

        // Don't calculate creases if we're a backface triangle
        if (u_CullBackfaceCreases && 
            isBackface(
                gsin[0].worldPosition.xyz, 
                gsin[1].worldPosition.xyz,
                gsin[2].worldPosition.xyz
            )
        ) {
            return;
        }

        if (u_SilhouetteDrawMode > 0) {
            SilhouetteInfo s = getSilhouetteInfo();
            if (s.valid) {
                // drawSilhouette(s);

                // Copy color forward to silhouette geometry.
                // And set alpha to 1.0 for detection in the PS
                o.color = gsin[0].color;
                o.color.a = 1.0;

                // TODO: Interpolate thickness at each end based
                // on the thickness value of adjacent vertices
                // (should be done within getSilhouetteInfo)
                drawEdge(
                    u_ModelMatrix * vec4(s.startPos, 1), 
                    u_ModelMatrix * vec4(s.endPos, 1), 
                    s.startNormal,
                    s.endNormal,
                    u_SilhouetteScale,
                    1.0,
                    1.0
                );
            }
        }

        if (u_CreaseDrawMode < 1) {
            return;
        }

        // If the entire triangle is marked with crease edges, ignore entirely.
        // It's at a junction we can't resolve.
        // if (gsin[0].color.a == gsin[2].color.a && gsin[0].color.a == gsin[4].color.a) {
        //     return;
        // }
        
        int lod = getLOD();

        // For every crease edge, draw a billboarded prismoid
        for (int idx = 0; idx < 6; idx += 2) {
            int nextIdx = (idx + 2) % 6;

            // Copy forward to all crease geometry
            o.color = gsin[idx].color;

            if (isValidCrease(idx, nextIdx, lod)) {
                // Extract thickness at each end
                // Stored in 'TT' decimal places of alpha 0.LBTT 
                float thickness = gsin[idx].color.a;
                float nextThickness = gsin[nextIdx].color.a;
                thickness = thickness * 100 - floor(thickness * 100);
                nextThickness = nextThickness * 100 - floor(nextThickness * 100);

                drawEdge(
                    gsin[idx].worldPosition, 
                    gsin[nextIdx].worldPosition,
                    gsin[idx].normal, 
                    gsin[nextIdx].normal,
                    u_CreaseScale,
                    thickness, 
                    nextThickness
                );
            }
        }
    }
}


GLSLShader PS
{
    struct EdgeInfo {
        // Distance between the fragment and the edge's line segment
        float segmentDistance;

        // Half of the screen space width of the edge
        float halfWidth;

        // If false, this edge is a crease. 
        bool silhouette;
    };

    /**
     * If the fragment is part of edge geometry, extract useful info for rendering
     */
    EdgeInfo getEdgeInfo() {
        EdgeInfo o;
        
        // Extract UV coordinates and edge half width
        vec2 uv = i.uv.xy;
        float uvHalfW = i.uv.z;
        uv.y *= uvHalfW * 2;

        // Generate a screen-space capsule by discarding fragments
        // that are further than uvHalfW from the crease edge
        vec2 start = vec2(uvHalfW, uvHalfW);
        vec2 end = vec2(1.0 - uvHalfW, uvHalfW);

        o.halfWidth = uvHalfW;
        o.segmentDistance = distanceToSegment(uv, start, end); 
        o.silhouette = i.color.a > 0.99;
        return o;
    }

    vec3 edgeLODToColor(float lod) {
        if (i.color.a >= 0.299) { // LOD2
            return vec3(0.01);
        } else if (i.color.a >= 0.199) { // LOD1
            return vec3(0.25);
        } else { // LOD0
            return vec3(1);
        }
    }

    /**
     * Determine final color of edge geometry, taking in account draw mode and edge type.
     */
    vec3 getEdgeColor(EdgeInfo info) {
        vec3 color;

        if (info.silhouette) {
            if (u_SilhouetteDrawMode == SILHOUETTE_DRAW_UVS) {
                color = vec3(i.uv.x, 0, i.uv.y);
            } else if (u_SilhouetteDrawMode == SILHOUETTE_DRAW_COLOR) {
                color = u_OutlineColor;
                
                if (u_UseVertexColors) {
                    color *= i.color.rgb;
                }
            }
        } else {
            if (u_CreaseDrawMode == CREASE_DRAW_UVS) {
                color = vec3(i.uv.x, 0, i.uv.y);
            } else if (u_CreaseDrawMode == CREASE_DRAW_LOD) {
                color = edgeLODToColor(i.color.a);
            } else if (u_CreaseDrawMode == CREASE_DRAW_COLOR) {
                color = u_OutlineColor;

                if (u_UseVertexColors) {
                    color *= i.color.rgb;
                }
            }
        }

        return color;
    }

    /**
     * @return 1 for fully in shadow, 0 for no contribution, anything in between for AA
     */
    float calculateShadowsContribution(mat4 lightViewProj, vec4 worldPos, float NdotL) {
        vec4 viewPos = lightViewProj * worldPos;

        // Correct for perspective
        vec3 perspViewPos = viewPos.xyz / viewPos.w;

        // No contribution if we're outside the light's view 
        if (perspViewPos.x < -1 || 
            perspViewPos.x > 1 || 
            perspViewPos.y < -1 || 
            perspViewPos.y > 1 || 
            perspViewPos.z < -1 || 
            perspViewPos.z > 1
        ) {
            return 1;
        }

        // Transform texture sample location from [-1, 1] to [0, 1] in UV coordinates
        vec2 uv = perspViewPos.xy * 0.5 + 0.5;

        // Position's depth from the light view
        float depth = perspViewPos.z; // - (0.01 / viewPos.w);

        // Sample depth map from light0 view and don't contribute if 
        // our depth is further from the light than sampled depth
        // Note that Maya only has depth information in the x
        // vec4 sampled = textureLod(light0ShadowMapSampler, uv, 0);

        // tan(acos(NdotL)) is used to modify our bias based on the 
        // slope for curved surfaces that end up artifacting
        // Source: http://www.opengl-tutorial.org/intermediate-tutorials/tutorial-16-shadow-mapping/
        float bias = 0.005 * tan(acos(NdotL));
        bias = clamp(bias, 0.0, 0.01) * 0.01;
        
        vec4 sampled = blur9(light0ShadowMapSampler, uv, vec2(512.0, 512.0) * 5.0, perspViewPos.xy * 5);
    
        // Not occluded, no shadow contribution.
        if (depth - sampled.x < bias) {
            return 0;
        }
        
        // Occluded, full shadow
        return 1;

        // An attempt at slight anti-aliasing of the edges.
        // It's pretty piss poor, but this is a good
        // spot for a TODO to replace with a better algorithm.

        // // Random offsets for poisson sampling of UV coordinates around our texel
        // // Samples come from: https://www.geeks3d.com/20100628/3d-programming-ready-to-use-64-sample-poisson-disc/
        // vec2 poissonDisk[16] = vec2[](
        //     vec2(-0.667531, 0.326090),
        //     vec2(-0.098422, -0.295755),
        //     vec2(-0.885922, 0.215369),
        //     vec2(0.566637, 0.605213),
        //     vec2(0.039766, -0.396100),
        //     vec2(0.751946, 0.453352),
        //     vec2(0.078707, -0.715323),
        //     vec2(-0.075838, -0.529344),
        //     vec2(0.724479, -0.580798),
        //     vec2(0.222999, -0.215125),
        //     vec2(-0.467574, -0.405438),
        //     vec2(-0.248268, -0.814753),
        //     vec2(0.354411, -0.887570),
        //     vec2(0.175817, 0.382366),
        //     vec2(0.487472, -0.063082),
        //     vec2(-0.084078, 0.898312)
        // );

        // float sum = 1;
        // // Poisson sampling of adjacent texels to get some mild AA going on.
        // // Numbers are trial and error and probably won't work for everything :^)
        // for (int i = 0; i < 8; i++) {
        //     if (depth - textureLod(light0ShadowMapSampler, uv + poissonDisk[i]/1000.0, 0).x < bias) {
        //         sum -= 0.125; // 1/8
        //     }
        // }

        // return sum;
    }

    /**
     * Returns contribution of the input light within (0, 1).
     *
     * For toon shading, 0 is shaded, 0.5 is lit diffuse, and 1.0 are highlights.
     * Depending on the material properties, certain channels will be mixed differently.
     *
     * @return float 
     */
    float calculateLightContribution(
        // Light arguments
        bool lightEnable, 
        int lightType, 
        vec3 lightPos, 
        vec3 lightDir, 
        vec3 lightColor,
        float lightIntensity, 
        float lightConeAngle,
        float lightFalloff,
        mat4 lightViewProj,
        // Fragment arguments
        vec4 worldPos,
        vec3 worldNormal,
        vec3 eyeDir
    ) {
        if (!lightEnable) {
            return 0;
        }

        // TODO: If ambient light - do a color mix and no additional
        // shadow mapping or whatever. (use light color + intensity for mix)

        vec3 lightVec = lightPos - worldPos.xyz;
        vec3 L = normalize(lightVec);
        float NdotL = dot(worldNormal, L);

        // Diffuse
        // float diffuse = smoothstep(0.0, 0.01, NdotL);
        // Above interferes with the fwidth method.
        float diffuse = 1 - step(max(0, NdotL * lightIntensity), 0.01);

        // Specular: I_incoming * k_specular * max(0, R dot V)^shininess
        // Where k_specular is the material specular constant
        float specular = 0;
        if (u_SpecularScale > 0) {
            vec3 V = normalize(u_CameraMatrix[3].xyz - worldPos.xyz);
            vec3 R = normalize(reflect(lightDir, worldNormal));
            specular = u_SpecularScale * dot(R, V);

            // Slight optimization - don't run high pow() unless we need to 
            if (specular > 0) {
                specular = clamp(pow(specular, u_Shininess), 0, 1);
            }

            // 2-tone tighten
            specular = 1.0 - step(max(0, specular), 0.01);
        }
        
        // Rim
        float rim = 0;
        if (u_RimScale > 0) {
            float rimDot = 1 - max(dot(eyeDir, worldNormal), 0);
            rim = rimDot; //* pow(NdotL, u_RimScale);
            // rim = smoothstep(0.2 - 0.01, 0.2 + 0.01, rim);
            // rim = smoothstep(0.0, 0.01, rim); 
            // rim = 1.0 - step(max(0, rim), 0.01);
        }
        
        // Shadow 
        float shadow = 0;
        if (u_ReceivesShadows) {
            shadow = calculateShadowsContribution(lightViewProj, worldPos, NdotL);
        }

        float decay = 1.0;

        // If we're a spotlight, decay around the cone
        if (lightType == LIGHT_TYPE_SPOT) {
            float LdotDir = dot(normalize(lightVec), -lightDir);
            // coneDecay = pow(clamp(LdotDir, 0.0, 1.0), 1 / lightConeAngle);
            decay = smoothstep(cos(lightFalloff), cos(lightConeAngle), LdotDir);
        }

        // float v = clamp(intensity / lightIntensity, 0.01, 0.99);
        // vec3 samp = texture2D(u_ShadowMapSampler, vec2(0, v)).xyz;

        if (u_IsolateLightContribution == ISOLATE_LIGHT_DIFFUSE) {
            return diffuse;
        }

        if (u_IsolateLightContribution == ISOLATE_LIGHT_SPECULAR) {
            return specular;
        }

        if (u_IsolateLightContribution == ISOLATE_LIGHT_RIM) {
            return rim;
        }

        if (u_IsolateLightContribution == ISOLATE_LIGHT_SHADOWS) {
            return shadow;
        }

        if (u_IsolateLightContribution == ISOLATE_LIGHT_DECAY) {
            return decay;
        }

        // TODO: Better mix rim + spec so there's no multiplicative overlap

        // for final mix, diffuse gets 
        return clamp(
            (diffuse * 0.5 + clamp(rim + specular, 0.0, 1.0)) * decay * (1 - shadow), 
            0.0, 
            1.0
        ); 

        // Default: mix 
        // return clamp(diffuse * (rim + specular) * decay * (1 - shadow), 0.0, 1.0);
    }

    /**
     * Determine final color of the original input geometry
     */
    vec3 getGeometryColor() {
        vec3 color;

        // Calculate lighting
        vec3 eyeDir = normalize(u_CameraMatrix[3].xyz - i.worldPosition.xyz);

        float light = 0.5;
        
        // Determine light/shadow contributions if lit
        if (!u_Unlit) {
            light = calculateLightContribution(
                light0Enable, 
                light0Type, 
                light0Pos,
                light0Dir,
                light0Color,
                light0Intensity,
                light0ConeAngle,
                light0FallOff,
                light0ViewProj,
                i.worldPosition,
                i.worldNormal,
                eyeDir
            );
        } 

        // Slight AA across light transitions. Not much of an MSAA 
        // replacement but does improve things a bit. 
        // Via: https://prideout.net/blog/old/blog/index.html@p=22.html
        float e = fwidth(light);
        if (light > 0.5 - e && light < 0.5 + e) {
            light = smoothstep(0.5 - e, 0.5 + e, light);
        }

        if (u_IsolateLightContribution > 0) {
            color = vec3(light);
        } else {
            if (u_UseVertexColors) {
                // Use vertex color for diffuse and mix with shaded.

                // light 0 is shaded, light 0.5 is diffuse lit, 1 is highlight
                if (light > 0.5) {
                    color = lerp(i.color.xyz, i.color.xyz / u_Specular, (light - 0.5) * 2.0);
                } else {
                    color = lerp(i.color.xyz * u_Shaded, i.color.xyz, light * 2.0);
                }
            } else {
                // Fixed diffuse + shade + specular color palette, lerp between
                if (light > 0.5) {
                    color = lerp(u_Diffuse, u_Specular, (light - 0.5) * 2.0);
                } else {
                    color = lerp(u_Shaded, u_Diffuse, light * 2.0);
                }

            }
        }

        // Wireframe rendering by lerping between a wireframe 
        // color and our actual output color based on how close the
        // fragment is to a triangle edge
        if (u_GeometryDrawMode == GEOMETRY_DRAW_WIREFRAME) {
            float d = min(i.dist.x, min(i.dist.y, i.dist.z)) * 2.0;
            // float intensity = exp2(-2.0 * d * d);
            d = smoothstep(0.025, 0.05, d);

            // draw the main color, but fade vertex edges on top of it
            // TODO: Distance based
            color = lerp(color, d * color, 0.1);
        }

        return color;
    }

    void main() {
        // If alpha channel is nonzero, we're flagged as edge geometry
        if (i.color.a >= 0.01) {
            EdgeInfo info = getEdgeInfo();

            // Generate a screen space capsule by discarding fragments
            // that are too far from the edge's line segment
            if (info.segmentDistance > info.halfWidth) {
                discard;
            }

            color = vec4(getEdgeColor(info), u_EdgeOpacity);
        } else {
            color = vec4(getGeometryColor(), 1.0);
        }
    }
}

attribute shadowdata {
    vec4 worldPosition : POSITION;
};

GLSLShader ShadowVS
{
    void main() {
        o.worldPosition = u_ModelMatrix * vec4(position, 1);
        gl_Position = u_ViewProjMatrix * o.worldPosition;
    }
}

/**
 * Shadow fragment shader from the perspective of attached light(s)
 *
 * Operates solely on the original geometry, as edges don't matter here.
 */ 
GLSLShader ShadowPS
{
    /**
     * Via Autodesk's Uber Shader
     */
    float getShadowDepth(vec4 worldPos, mat4 shadowProjMatrix) {
        vec4 mul = shadowProjMatrix * worldPos;
        float depthPerPixel = mul.z / mul.w;
        return (depthPerPixel + fwidth(depthPerPixel)) * 0.5 + 0.5;
    }

    void main() {
        if (!u_CastsShadows) {
            discard;
        }

        // Dotted shadow, for verifying we're actually running
        // if (int(gl_FragCoord.x) % 2 > 0 && int(gl_FragCoord.y) % 2 > 0) discard;
        float depth = getShadowDepth(psin.worldPosition, u_ViewProjMatrix);
        color = vec4(depth, depth, depth, 1);
    }
}

technique Main
<
    // string Transparency = "Opaque";
    // string Transparency = "Transparent";
    string index_buffer_type = "GLSL_TRIADJ";
>
{
	pass p0
    <
        string drawContext = "colorPass";
    >
	{
		VertexShader (in appdata, out vs_to_gs o) = VS;
		GeometryShader (in vs_to_gs gsin, out gs_to_ps o) = GS;
		PixelShader (in gs_to_ps i, out ps_out) = { Utility, PS };
	}
    
    // Shadow cast pass. Not working for some reason - probably b/c of missing GS.
    // Skipping for now since it just mimics Maya's shadow casting anyway.
    pass p1
    <
        string drawContext = "shadowPass";
    >
    {
		VertexShader (in appdata, out shadowdata o) = ShadowVS;
		PixelShader (in shadowdata psin, out ps_out) = ShadowPS;
    }
}
